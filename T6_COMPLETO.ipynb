{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fatal-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter #este va servir para exportar achivos a excel\n",
    "import xlrd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hollow-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>GR_EDTC</th>\n",
       "      <th>RHOZ</th>\n",
       "      <th>AT90</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>DTCO</th>\n",
       "      <th>GRAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3484.5061</td>\n",
       "      <td>88.9094</td>\n",
       "      <td>2.4670</td>\n",
       "      <td>8.8005</td>\n",
       "      <td>0.3477</td>\n",
       "      <td>92.01340</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3484.0056</td>\n",
       "      <td>84.1737</td>\n",
       "      <td>2.4635</td>\n",
       "      <td>8.8252</td>\n",
       "      <td>0.3383</td>\n",
       "      <td>91.57937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3483.5027</td>\n",
       "      <td>85.9207</td>\n",
       "      <td>2.4642</td>\n",
       "      <td>9.2523</td>\n",
       "      <td>0.3422</td>\n",
       "      <td>91.48260</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3483.0022</td>\n",
       "      <td>85.2922</td>\n",
       "      <td>2.4670</td>\n",
       "      <td>9.7221</td>\n",
       "      <td>0.3252</td>\n",
       "      <td>91.13451</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3482.5049</td>\n",
       "      <td>89.9095</td>\n",
       "      <td>2.4710</td>\n",
       "      <td>9.6451</td>\n",
       "      <td>0.3186</td>\n",
       "      <td>91.07773</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DEPTH  GR_EDTC    RHOZ    AT90    NPHI      DTCO  GRAY\n",
       "0  3484.5061  88.9094  2.4670  8.8005  0.3477  92.01340   0.0\n",
       "1  3484.0056  84.1737  2.4635  8.8252  0.3383  91.57937   0.0\n",
       "2  3483.5027  85.9207  2.4642  9.2523  0.3422  91.48260   0.0\n",
       "3  3483.0022  85.2922  2.4670  9.7221  0.3252  91.13451   0.0\n",
       "4  3482.5049  89.9095  2.4710  9.6451  0.3186  91.07773   0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#para encontrar una grafica de excel y ponerla en python \n",
    "datos = \"ML-Wells.xlsx\" #busco el archivo y lo pego con el indicativo por ejemplo .xlsx\n",
    "df = pd.read_excel(datos, sheet_name=\"T6\")#sacar del excel a python\n",
    "df.drop(columns= [\"PHOTO\",\"WELL\",\"Unnamed: 0\"], inplace=True) #para borrar una columna que no queremos\n",
    "df.sort_values(by=\"DEPTH\")\n",
    "#print(df.shape) #para saber el tamaño de como quedo antes de borrar los valore nulos\n",
    "df.dropna(inplace=True)\n",
    "df.set_index(np.array(range(0,(df.shape)[0])), inplace=True)\n",
    "print(df.shape) #para saber el tamaño de como quedo despues de borrar \n",
    "#df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "violent-health",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    190\n",
       "1.0     26\n",
       "Name: cutoff, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray = np.array(df.loc[:,'GRAY']) # crea un vector nuev0 todas las filas que tenga la columna GRAY\n",
    "cutoff = np.zeros(gray.shape) \n",
    "# hacemos el condicional\n",
    "cut_off = 250\n",
    "for i in range (gray.shape[0]):\n",
    "  if (gray[i] >= 140):\n",
    "    cutoff[i] = 1\n",
    "\n",
    "df['cutoff'] = cutoff\n",
    "df[\"cutoff\"].value_counts() #esto sirve para saber cuantos valores de 1 y de 0 que hay en el cutoff hay \n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adjusted-california",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de Entrenamiento:  151\n",
      "Tamaño de Prueba:  65\n"
     ]
    }
   ],
   "source": [
    "#Definición de Vector de Salida y Partición en Train y Test Stratified\n",
    "from sklearn.model_selection import StratifiedShuffleSplit #la dicision de 70 y 30 halla quede propocional los valores de salida de 100% proporsional en ambos parametros de porcentaje\n",
    "from sklearn.preprocessing import StandardScaler #esto sirve para normalizar los datos osea sacar el max y el minimo yy dividir todos los valores por el maximo para todas las columnas queden en un ranco de 0 a 1\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)#tamaño de prueba\n",
    "for train_index, test_index in split.split(df, df[\"cutoff\"].values):\n",
    "    Xtrain_strat = df.loc[train_index]\n",
    "    Xtest_strat = df.loc[test_index]\n",
    "\n",
    "ytrain_strat = np.array(Xtrain_strat['cutoff'])\n",
    "ytest_strat = np.array(Xtest_strat['cutoff'])\n",
    "Xtrain_strat.drop(columns='cutoff', inplace=True)\n",
    "Xtest_strat.drop(columns='cutoff', inplace=True)\n",
    "\n",
    "#Normalización de los datos\n",
    "normalizar = StandardScaler()\n",
    "Xtest_strat = normalizar.fit_transform(Xtest_strat)\n",
    "\n",
    "print(\"Tamaño de Entrenamiento: \",Xtrain_strat.shape[0])\n",
    "print(\"Tamaño de Prueba: \",Xtest_strat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "agreed-julian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando: PCA - RandomForest \n",
      "\n",
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n",
      "\n",
      "Mejores parámetros con PCA - RandomForest : {'class__max_depth': 12, 'class__n_estimators': 20, 'rep__n_components': 7}\n",
      "\n",
      "Cros-Score con PCA - RandomForest : 0.694\n",
      "\n",
      "\n",
      "Entrenando: Random Forest \n",
      "\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "Mejores parámetros con Random Forest : {'class__max_depth': 8, 'class__n_estimators': 20}\n",
      "\n",
      "Cros-Score con Random Forest : 0.889\n",
      "\n",
      "\n",
      "Entrenando: PCA - SVC \n",
      "\n",
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n",
      "\n",
      "Mejores parámetros con PCA - SVC : {'class__C': 100, 'class__gamma': 0.001, 'rep__n_components': 6}\n",
      "\n",
      "Cros-Score con PCA - SVC : 0.871\n",
      "\n",
      "\n",
      "Entrenando: SVC \n",
      "\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "Mejores parámetros con SVC : {'class__C': 100, 'class__gamma': 0.001}\n",
      "\n",
      "Cros-Score con SVC : 0.871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definición de Pasos y Parámetros\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score, cross_val_predict \n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import joblib\n",
    "# pasos que debe hacer con los datos #pca es un algoritmo para hacer reduccion de dimecion \n",
    "steps=[[('norm', StandardScaler()),\n",
    "        ('rep', PCA()),\n",
    "       ('class', RandomForestClassifier())],\n",
    "       [('norm', StandardScaler()),\n",
    "        ('class', RandomForestClassifier())],\n",
    "       [('norm', StandardScaler()),\n",
    "        ('rep', PCA()),\n",
    "        ('class', SVC())],\n",
    "       [('norm', StandardScaler()),\n",
    "        ('class', SVC())],]\n",
    "# con que parametros quiero que haga lo que esta arriba\n",
    "parameters = [{'rep__n_components':[2,4,7],\n",
    "              'class__max_depth': [8,10,12,15],\n",
    "              'class__n_estimators' : [20,40,60,80,100]\n",
    "              }, \n",
    "              {'class__max_depth': [8,10,12,15],\n",
    "              'class__n_estimators' : [20,40,60,80,100]\n",
    "              },\n",
    "              {'rep__n_components':[2,4,6,7],\n",
    "              'class__C': [1,20,50,100,150],\n",
    "              'class__gamma': [0.01, 0.001, 0.0001]\n",
    "              },\n",
    "              {'class__C': [1,20,50,100,150],\n",
    "               'class__gamma': [0.01, 0.001, 0.0001]\n",
    "              }]\n",
    "\n",
    "cross_scores_strat = {} #puntaje de precision\n",
    "err_strat = []\n",
    "conf_matrxs_strat = []\n",
    "best_model_strat = []\n",
    "filename_strat = 'modelos_class'#'resultados/people_comp'\n",
    "tests_strat = ['PCA - RandomForest','Random Forest','PCA - SVC','SVC']\n",
    "\n",
    "for i in range (len(steps)):\n",
    "    pipeline = Pipeline(steps = steps[i])\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, parameters[i], n_jobs=-1,cv=3,\n",
    "                               scoring='balanced_accuracy',verbose=5) #balanceado\n",
    "    \n",
    "    print(\"\\nEntrenando: {} \\n\".format(tests_strat[i]))\n",
    "    grid_search.fit(Xtrain_strat, ytrain_strat)\n",
    "    \n",
    "    #mejor modelo entrenado\n",
    "    best_model_n = grid_search.best_estimator_\n",
    "    best_model_strat += [grid_search.best_estimator_]\n",
    "    joblib.dump(best_model_strat,filename_strat+\".pkl\")\n",
    "    print(\"\\nMejores parámetros con {} : {}\".format(tests_strat[i],grid_search.best_params_))\n",
    "    \n",
    "    #evaluación:\n",
    "    ytest_pred = cross_val_predict(best_model_n, Xtest_strat, ytest_strat, cv=3)\n",
    "    cross_score = np.mean(cross_val_score(best_model_n, Xtest_strat, ytest_strat, cv=3, scoring=\"balanced_accuracy\"))\n",
    "    cross_scores_strat[tests_strat[i]] = cross_score\n",
    "    conf_matrx = confusion_matrix(ytest_strat, ytest_pred, normalize= 'true')\n",
    "\n",
    "    print(\"\\nCros-Score con {} : {:.3f}\\n\".format(tests_strat[i],cross_score))\n",
    "    err_strat.append(cross_score)\n",
    "    conf_matrxs_strat.append(conf_matrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "theoretical-hartford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validación: \n",
      " {'PCA - RandomForest': 0.6944444444444443, 'Random Forest': 0.8888888888888888, 'PCA - SVC': 0.871345029239766, 'SVC': 0.871345029239766}\n"
     ]
    }
   ],
   "source": [
    "print(\"Validación: \\n\", cross_scores_strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-ready",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
