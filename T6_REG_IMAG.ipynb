{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "geographic-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter #este va servir para exportar achivos a excel\n",
    "import xlrd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "combined-senior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67896, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>GRAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>804.000000</td>\n",
       "      <td>91.7625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804.000795</td>\n",
       "      <td>98.2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>804.001591</td>\n",
       "      <td>101.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>804.002386</td>\n",
       "      <td>96.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>804.003181</td>\n",
       "      <td>98.0625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DEPTH      GRAY\n",
       "0  804.000000   91.7625\n",
       "1  804.000795   98.2125\n",
       "2  804.001591  101.8750\n",
       "3  804.002386   96.8125\n",
       "4  804.003181   98.0625"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#para encontrar una grafica de excel y ponerla en python \n",
    "datos = \"Processed_Images_T6.xlsx\" #busco el archivo y lo pego con el indicativo por ejemplo .xlsx\n",
    "df = pd.read_excel(datos, sheet_name=\"T6\")#sacar del excel a python\n",
    "df.drop(columns= [\"#\",\"PHOTO\"], inplace=True) #para borrar una columna que no queremos\n",
    "df.sort_values(by=\"DEPTH\")\n",
    "#print(df.shape) #para saber el tamaño de como quedo antes de borrar los valore nulos\n",
    "df.dropna(inplace=True)\n",
    "df.set_index(np.array(range(0,(df.shape)[0])), inplace=True)\n",
    "print(df.shape) #para saber el tamaño de como quedo despues de borrar \n",
    "#df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amazing-geology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    47384\n",
       "1.0    20512\n",
       "Name: cutoff, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray = np.array(df.loc[:,'GRAY']) # crea un vector nuev0 todas las filas que tenga la columna GRAY\n",
    "cutoff = np.zeros(gray.shape) \n",
    "# hacemos el condicional\n",
    "cut_off = 250\n",
    "for i in range (gray.shape[0]):\n",
    "  if (gray[i] >= 80):\n",
    "    cutoff[i] = 1\n",
    "\n",
    "df['cutoff'] = cutoff\n",
    "df[\"cutoff\"].value_counts() #esto sirve para saber cuantos valores de 1 y de 0 que hay en el cutoff hay \n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "peaceful-interim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de Entrenamiento:  47527\n",
      "Tamaño de Prueba:  20369\n"
     ]
    }
   ],
   "source": [
    "#Definición de Vector de Salida y Partición en Train y Test Stratified\n",
    "from sklearn.model_selection import StratifiedShuffleSplit #la dicision de 70 y 30 halla quede propocional los valores de salida de 100% proporsional en ambos parametros de porcentaje\n",
    "from sklearn.preprocessing import StandardScaler #esto sirve para normalizar los datos osea sacar el max y el minimo yy dividir todos los valores por el maximo para todas las columnas queden en un ranco de 0 a 1\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)#tamaño de prueba\n",
    "for train_index, test_index in split.split(df, df[\"cutoff\"].values):\n",
    "    Xtrain_strat = df.loc[train_index]\n",
    "    Xtest_strat = df.loc[test_index]\n",
    "\n",
    "ytrain_strat = np.array(Xtrain_strat['cutoff'])\n",
    "ytest_strat = np.array(Xtest_strat['cutoff'])\n",
    "Xtrain_strat.drop(columns='cutoff', inplace=True)\n",
    "Xtest_strat.drop(columns='cutoff', inplace=True)\n",
    "\n",
    "#Normalización de los datos\n",
    "normalizar = StandardScaler()\n",
    "Xtest_strat = normalizar.fit_transform(Xtest_strat)\n",
    "\n",
    "print(\"Tamaño de Entrenamiento: \",Xtrain_strat.shape[0])\n",
    "print(\"Tamaño de Prueba: \",Xtest_strat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "smooth-field",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando: PCA - RandomForest \n",
      "\n",
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\VCThesis\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.99933158        nan        nan 0.99913199        nan        nan\n",
      " 0.99912731        nan        nan 0.99916681        nan        nan\n",
      " 0.99926661        nan        nan 0.99925153        nan        nan\n",
      " 0.99914706        nan        nan 0.99919696        nan        nan\n",
      " 0.99916214        nan        nan 0.99918188        nan        nan\n",
      " 0.99928636        nan        nan 0.99915746        nan        nan\n",
      " 0.99916214        nan        nan 0.99923646        nan        nan\n",
      " 0.99925726        nan        nan 0.99914238        nan        nan\n",
      " 0.99913666        nan        nan 0.99914239        nan        nan\n",
      " 0.99912731        nan        nan 0.99923178        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejores parámetros con PCA - RandomForest : {'class__max_depth': 8, 'class__n_estimators': 20, 'rep__n_components': 2}\n",
      "\n",
      "Cros-Score con PCA - RandomForest : 0.999\n",
      "\n",
      "\n",
      "Entrenando: Random Forest \n",
      "\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "Mejores parámetros con Random Forest : {'class__max_depth': 8, 'class__n_estimators': 60}\n",
      "\n",
      "Cros-Score con Random Forest : 1.000\n",
      "\n",
      "\n",
      "Entrenando: PCA - SVC \n",
      "\n",
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\VCThesis\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.99640152        nan        nan        nan 0.97814757        nan\n",
      "        nan        nan 0.95863307        nan        nan        nan\n",
      " 0.99900567        nan        nan        nan 0.99713445        nan\n",
      "        nan        nan 0.98963593        nan        nan        nan\n",
      " 0.99968449        nan        nan        nan 0.99798949        nan\n",
      "        nan        nan 0.99432756        nan        nan        nan\n",
      " 0.99981443        nan        nan        nan 0.99847549        nan\n",
      "        nan        nan 0.99632147        nan        nan        nan\n",
      " 0.99962991        nan        nan        nan 0.99893602        nan\n",
      "        nan        nan 0.99688858        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejores parámetros con PCA - SVC : {'class__C': 100, 'class__gamma': 0.01, 'rep__n_components': 2}\n",
      "\n",
      "Cros-Score con PCA - SVC : 1.000\n",
      "\n",
      "\n",
      "Entrenando: SVC \n",
      "\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "Mejores parámetros con SVC : {'class__C': 100, 'class__gamma': 0.01}\n",
      "\n",
      "Cros-Score con SVC : 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definición de Pasos y Parámetros\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score, cross_val_predict \n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import joblib\n",
    "# pasos que debe hacer con los datos #pca es un algoritmo para hacer reduccion de dimecion \n",
    "steps=[[('norm', StandardScaler()),\n",
    "        ('rep', PCA()),\n",
    "       ('class', RandomForestClassifier())],\n",
    "       [('norm', StandardScaler()),\n",
    "        ('class', RandomForestClassifier())],\n",
    "       [('norm', StandardScaler()),\n",
    "        ('rep', PCA()),\n",
    "        ('class', SVC())],\n",
    "       [('norm', StandardScaler()),\n",
    "        ('class', SVC())],]\n",
    "# con que parametros quiero que haga lo que esta arriba\n",
    "parameters = [{'rep__n_components':[2,4,7],\n",
    "              'class__max_depth': [8,10,12,15],\n",
    "              'class__n_estimators' : [20,40,60,80,100]\n",
    "              }, \n",
    "              {'class__max_depth': [8,10,12,15],\n",
    "              'class__n_estimators' : [20,40,60,80,100]\n",
    "              },\n",
    "              {'rep__n_components':[2,4,6,7],\n",
    "              'class__C': [1,20,50,100,150],\n",
    "              'class__gamma': [0.01, 0.001, 0.0001]\n",
    "              },\n",
    "              {'class__C': [1,20,50,100,150],\n",
    "               'class__gamma': [0.01, 0.001, 0.0001]\n",
    "              }]\n",
    "\n",
    "cross_scores_strat = {} #puntaje de precision\n",
    "err_strat = []\n",
    "conf_matrxs_strat = []\n",
    "best_model_strat = []\n",
    "filename_strat = 'modelos_class'#'resultados/people_comp'\n",
    "tests_strat = ['PCA - RandomForest','Random Forest','PCA - SVC','SVC']\n",
    "\n",
    "for i in range (len(steps)):\n",
    "    pipeline = Pipeline(steps = steps[i])\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, parameters[i], n_jobs=-1,cv=3,\n",
    "                               scoring='balanced_accuracy',verbose=5) #balanceado\n",
    "    \n",
    "    print(\"\\nEntrenando: {} \\n\".format(tests_strat[i]))\n",
    "    grid_search.fit(Xtrain_strat, ytrain_strat)\n",
    "    \n",
    "    #mejor modelo entrenado\n",
    "    best_model_n = grid_search.best_estimator_\n",
    "    best_model_strat += [grid_search.best_estimator_]\n",
    "    joblib.dump(best_model_strat,filename_strat+\".pkl\")\n",
    "    print(\"\\nMejores parámetros con {} : {}\".format(tests_strat[i],grid_search.best_params_))\n",
    "    \n",
    "    #evaluación:\n",
    "    ytest_pred = cross_val_predict(best_model_n, Xtest_strat, ytest_strat, cv=3)\n",
    "    cross_score = np.mean(cross_val_score(best_model_n, Xtest_strat, ytest_strat, cv=3, scoring=\"balanced_accuracy\"))\n",
    "    cross_scores_strat[tests_strat[i]] = cross_score\n",
    "    conf_matrx = confusion_matrix(ytest_strat, ytest_pred, normalize= 'true')\n",
    "\n",
    "    print(\"\\nCros-Score con {} : {:.3f}\\n\".format(tests_strat[i],cross_score))\n",
    "    err_strat.append(cross_score)\n",
    "    conf_matrxs_strat.append(conf_matrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "worse-photographer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validación: \n",
      " {'PCA - RandomForest': 0.9985325718937464, 'Random Forest': 0.9999187784275504, 'PCA - SVC': 0.9995670793679907, 'SVC': 0.9995670793679907}\n"
     ]
    }
   ],
   "source": [
    "print(\"Validación: \\n\", cross_scores_strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-lafayette",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
