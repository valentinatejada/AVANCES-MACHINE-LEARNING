{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "attractive-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter #este va servir para exportar achivos a excel\n",
    "import xlrd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "crude-appearance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>GRAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3671.000000</td>\n",
       "      <td>28.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3671.001875</td>\n",
       "      <td>27.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3671.003750</td>\n",
       "      <td>27.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3671.005625</td>\n",
       "      <td>28.4625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3671.007500</td>\n",
       "      <td>29.5625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DEPTH     GRAY\n",
       "0  3671.000000  28.6000\n",
       "1  3671.001875  27.9250\n",
       "2  3671.003750  27.3750\n",
       "3  3671.005625  28.4625\n",
       "4  3671.007500  29.5625"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#para encontrar una grafica de excel y ponerla en python \n",
    "datos = \"Processed_Images_T2.xlsx\" #busco el archivo y lo pego con el indicativo por ejemplo .xlsx\n",
    "df = pd.read_excel(datos, sheet_name=\"T2\")#sacar del excel a python\n",
    "df.drop(columns= [\"#\",\"PHOTO\"], inplace=True) #para borrar una columna que no queremos\n",
    "df.sort_values(by=\"DEPTH\")\n",
    "#print(df.shape) #para saber el tamaño de como quedo antes de borrar los valore nulos\n",
    "df.dropna(inplace=True)\n",
    "df.set_index(np.array(range(0,(df.shape)[0])), inplace=True)\n",
    "print(df.shape) #para saber el tamaño de como quedo despues de borrar \n",
    "#df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "combined-final",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    25332\n",
       "0.0    22668\n",
       "Name: cutoff, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray = np.array(df.loc[:,'GRAY']) # crea un vector nuev0 todas las filas que tenga la columna GRAY\n",
    "cutoff = np.zeros(gray.shape) \n",
    "# hacemos el condicional\n",
    "cut_off = 250\n",
    "for i in range (gray.shape[0]):\n",
    "  if (gray[i] >= 80):\n",
    "    cutoff[i] = 1\n",
    "\n",
    "df['cutoff'] = cutoff\n",
    "df[\"cutoff\"].value_counts() #esto sirve para saber cuantos valores de 1 y de 0 que hay en el cutoff hay \n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "coated-impression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de Entrenamiento:  33600\n",
      "Tamaño de Prueba:  14400\n"
     ]
    }
   ],
   "source": [
    "#Definición de Vector de Salida y Partición en Train y Test Stratified\n",
    "from sklearn.model_selection import StratifiedShuffleSplit #la dicision de 70 y 30 halla quede propocional los valores de salida de 100% proporsional en ambos parametros de porcentaje\n",
    "from sklearn.preprocessing import StandardScaler #esto sirve para normalizar los datos osea sacar el max y el minimo yy dividir todos los valores por el maximo para todas las columnas queden en un ranco de 0 a 1\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)#tamaño de prueba\n",
    "for train_index, test_index in split.split(df, df[\"cutoff\"].values):\n",
    "    Xtrain_strat = df.loc[train_index]\n",
    "    Xtest_strat = df.loc[test_index]\n",
    "\n",
    "ytrain_strat = np.array(Xtrain_strat['cutoff'])\n",
    "ytest_strat = np.array(Xtest_strat['cutoff'])\n",
    "Xtrain_strat.drop(columns='cutoff', inplace=True)\n",
    "Xtest_strat.drop(columns='cutoff', inplace=True)\n",
    "\n",
    "#Normalización de los datos\n",
    "normalizar = StandardScaler()\n",
    "Xtest_strat = normalizar.fit_transform(Xtest_strat)\n",
    "\n",
    "print(\"Tamaño de Entrenamiento: \",Xtrain_strat.shape[0])\n",
    "print(\"Tamaño de Prueba: \",Xtest_strat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "viral-anger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando: PCA - RandomForest \n",
      "\n",
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\VCThesis\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.99731485        nan        nan 0.99713905        nan        nan\n",
      " 0.9971258         nan        nan 0.99737456        nan        nan\n",
      " 0.99726508        nan        nan 0.99758685        nan        nan\n",
      " 0.99790363        nan        nan 0.99777426        nan        nan\n",
      " 0.99764654        nan        nan 0.99775933        nan        nan\n",
      " 0.99774104        nan        nan 0.99761835        nan        nan\n",
      " 0.99785053        nan        nan 0.99794506        nan        nan\n",
      " 0.99778419        nan        nan 0.99762497        nan        nan\n",
      " 0.99797656        nan        nan 0.9976117         nan        nan\n",
      " 0.99782565        nan        nan 0.99788536        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejores parámetros con PCA - RandomForest : {'class__max_depth': 15, 'class__n_estimators': 40, 'rep__n_components': 2}\n",
      "\n",
      "Cros-Score con PCA - RandomForest : 0.996\n",
      "\n",
      "\n",
      "Entrenando: Random Forest \n",
      "\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "Mejores parámetros con Random Forest : {'class__max_depth': 8, 'class__n_estimators': 20}\n",
      "\n",
      "Cros-Score con Random Forest : 1.000\n",
      "\n",
      "\n",
      "Entrenando: PCA - SVC \n",
      "\n",
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\VCThesis\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.99420213        nan        nan        nan 0.99354045        nan\n",
      "        nan        nan 0.9781867         nan        nan        nan\n",
      " 0.99918405        nan        nan        nan 0.99647081        nan\n",
      "        nan        nan 0.9910196         nan        nan        nan\n",
      " 0.99891039        nan        nan        nan 0.99804633        nan\n",
      "        nan        nan 0.99300475        nan        nan        nan\n",
      " 0.99909942        nan        nan        nan 0.99886561        nan\n",
      "        nan        nan 0.99426514        nan        nan        nan\n",
      " 0.99892361        nan        nan        nan 0.99899166        nan\n",
      "        nan        nan 0.99552549        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejores parámetros con PCA - SVC : {'class__C': 20, 'class__gamma': 0.01, 'rep__n_components': 2}\n",
      "\n",
      "Cros-Score con PCA - SVC : 0.998\n",
      "\n",
      "\n",
      "Entrenando: SVC \n",
      "\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "\n",
      "Mejores parámetros con SVC : {'class__C': 20, 'class__gamma': 0.01}\n",
      "\n",
      "Cros-Score con SVC : 0.998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Definición de Pasos y Parámetros\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score, cross_val_predict \n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import joblib\n",
    "# pasos que debe hacer con los datos #pca es un algoritmo para hacer reduccion de dimecion \n",
    "steps=[[('norm', StandardScaler()),\n",
    "        ('rep', PCA()),\n",
    "       ('class', RandomForestClassifier())],\n",
    "       [('norm', StandardScaler()),\n",
    "        ('class', RandomForestClassifier())],\n",
    "       [('norm', StandardScaler()),\n",
    "        ('rep', PCA()),\n",
    "        ('class', SVC())],\n",
    "       [('norm', StandardScaler()),\n",
    "        ('class', SVC())],]\n",
    "# con que parametros quiero que haga lo que esta arriba\n",
    "parameters = [{'rep__n_components':[2,4,7],\n",
    "              'class__max_depth': [8,10,12,15],\n",
    "              'class__n_estimators' : [20,40,60,80,100]\n",
    "              }, \n",
    "              {'class__max_depth': [8,10,12,15],\n",
    "              'class__n_estimators' : [20,40,60,80,100]\n",
    "              },\n",
    "              {'rep__n_components':[2,4,6,7],\n",
    "              'class__C': [1,20,50,100,150],\n",
    "              'class__gamma': [0.01, 0.001, 0.0001]\n",
    "              },\n",
    "              {'class__C': [1,20,50,100,150],\n",
    "               'class__gamma': [0.01, 0.001, 0.0001]\n",
    "              }]\n",
    "\n",
    "cross_scores_strat = {} #puntaje de precision\n",
    "err_strat = []\n",
    "conf_matrxs_strat = []\n",
    "best_model_strat = []\n",
    "filename_strat = 'modelos_class'#'resultados/people_comp'\n",
    "tests_strat = ['PCA - RandomForest','Random Forest','PCA - SVC','SVC']\n",
    "\n",
    "for i in range (len(steps)):\n",
    "    pipeline = Pipeline(steps = steps[i])\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, parameters[i], n_jobs=-1,cv=3,\n",
    "                               scoring='balanced_accuracy',verbose=5) #balanceado\n",
    "    \n",
    "    print(\"\\nEntrenando: {} \\n\".format(tests_strat[i]))\n",
    "    grid_search.fit(Xtrain_strat, ytrain_strat)\n",
    "    \n",
    "    #mejor modelo entrenado\n",
    "    best_model_n = grid_search.best_estimator_\n",
    "    best_model_strat += [grid_search.best_estimator_]\n",
    "    joblib.dump(best_model_strat,filename_strat+\".pkl\")\n",
    "    print(\"\\nMejores parámetros con {} : {}\".format(tests_strat[i],grid_search.best_params_))\n",
    "    \n",
    "    #evaluación:\n",
    "    ytest_pred = cross_val_predict(best_model_n, Xtest_strat, ytest_strat, cv=3)\n",
    "    cross_score = np.mean(cross_val_score(best_model_n, Xtest_strat, ytest_strat, cv=3, scoring=\"balanced_accuracy\"))\n",
    "    cross_scores_strat[tests_strat[i]] = cross_score\n",
    "    conf_matrx = confusion_matrix(ytest_strat, ytest_pred, normalize= 'true')\n",
    "\n",
    "    print(\"\\nCros-Score con {} : {:.3f}\\n\".format(tests_strat[i],cross_score))\n",
    "    err_strat.append(cross_score)\n",
    "    conf_matrxs_strat.append(conf_matrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "above-estate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validación: \n",
      " {'PCA - RandomForest': 0.9964474634605468, 'Random Forest': 0.999802683504341, 'PCA - SVC': 0.9977363318871452, 'SVC': 0.9977363318871452}\n"
     ]
    }
   ],
   "source": [
    "print(\"Validación: \\n\", cross_scores_strat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-theorem",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
